{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "681bd4f6-783b-46cf-a5de-ff646250f1bb",
          "showTitle": false,
          "title": ""
        },
        "id": "UGMVNrUtWBtB"
      },
      "source": [
        "# App Threads Automated Tagging V1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1fb94660-1346-43cb-b4e7-beb3cb78d2c7",
          "showTitle": false,
          "title": ""
        },
        "id": "wbBOVbP9WBtE"
      },
      "outputs": [],
      "source": [
        "!pip install deep-translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "832e3028-b3aa-4500-9131-be2c92a08593",
          "showTitle": false,
          "title": ""
        },
        "id": "iARO4HsJWBtF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from deep_translator import GoogleTranslator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "17cda054-99c2-4ad9-aafd-ff2702d029d0",
          "showTitle": false,
          "title": ""
        },
        "id": "N5oEjNs2WBtF"
      },
      "outputs": [],
      "source": [
        "spark.conf.set('spark.databricks.delta.formatCheck.enabled', False)\n",
        "spark.conf.set('spark.sql.legacy.timeParserPolicy', 'LEGACY')\n",
        "spark.conf.set('spark.sql.shuffle.partitions', 'auto')\n",
        "spark.conf.set(\"spark.databricks.adaptive.autoOptimizeShuffle.enabled\", \"true\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "ba1b5591-2f4d-4616-8492-04688a3ce3de",
          "showTitle": false,
          "title": ""
        },
        "id": "vH9tlp26WBtF"
      },
      "source": [
        "# Create Base Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "72215f8f-099d-4849-9663-d673d549ac85",
          "showTitle": false,
          "title": ""
        },
        "id": "RMEhuRp-WBtG"
      },
      "outputs": [],
      "source": [
        "start_dt = '2022-06-01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "38d12af0-b096-4555-b325-ac8990841cd4",
          "showTitle": false,
          "title": ""
        },
        "id": "VVnYeNMYWBtG"
      },
      "outputs": [],
      "source": [
        "@udf(returnType=StringType())\n",
        "def strip_html(text):\n",
        "  clean = re.compile('<.*?>')\n",
        "  return re.sub(clean, '', text)\n",
        "\n",
        "\n",
        "def thread_text_input(start_date):\n",
        "\n",
        "  thread_df = spark.sql(\n",
        "    r'''\n",
        "    select\n",
        "      thread_id,\n",
        "      thread_card_name,\n",
        "      content_language,\n",
        "      array_join(collect_set(card_title), ', ') as card_title,\n",
        "      array_join(collect_set(card_subtitle), ', ') as card_subtitle,\n",
        "      array_join(collect_set(card_body), ', ') as card_body,\n",
        "      array_join(collect_list(action_text), ', ') as action_text,\n",
        "      array_join(collect_list(destination_type), ', ') as action_destination_type,\n",
        "      -- char(round(avg(thread_card_count))) as thread_card_count,\n",
        "      max(brand) as brand,\n",
        "      max(targetted_interest_labels) as targetted_interest_labels,\n",
        "      max(brand_offerings_l1) as brand_offerings_l1,\n",
        "      max(brand_offerings_l2) as brand_offerings_l2,\n",
        "      max(split(marketing_creative_type, ',') [0]) as marketing_type,\n",
        "      max(thread_card.marketing_category) as marketing_category,\n",
        "      max(\n",
        "        regexp_replace(\n",
        "          regexp_replace(\n",
        "            regexp_extract(marketing_category, '(,|^)[a-zA-Z \\\\\\']+\\\\(Category, Dimension\\\\)', 0),\n",
        "            '\\\\(Category, Dimension\\\\)', ''\n",
        "            ),\n",
        "          '^[,| ]+|[,| ]+$', ''\n",
        "          )\n",
        "      ) as sport_dimension,\n",
        "      max(\n",
        "        regexp_replace(\n",
        "          regexp_replace(\n",
        "            regexp_extract(marketing_category, '(,|^)[a-zA-Z \\\\\\']+\\\\(Category, Construct\\\\)', 0),\n",
        "            '\\\\(Category, Construct\\\\)', ''\n",
        "          ),\n",
        "          '^[,| ]+|[,| ]+$', ''\n",
        "        )\n",
        "      ) as construct,\n",
        "      max(\n",
        "        regexp_replace(\n",
        "          regexp_replace(\n",
        "            regexp_extract(marketing_category, '(,|^)[a-zA-Z \\\\\\']+\\\\(Field of Play\\\\)', 0),\n",
        "            '\\\\(Field of Play\\\\)', ''\n",
        "          ),\n",
        "          '^[,| ]+|[,| ]+$', ''\n",
        "        )\n",
        "      ) as field_of_play\n",
        "    from\n",
        "      (\n",
        "        select\n",
        "          distinct thread_id,\n",
        "          CARD_KEY,\n",
        "          thread_card_name,\n",
        "          card_subtype,\n",
        "          card_title,\n",
        "          card_subtitle,\n",
        "          card_body,\n",
        "          thread_card_count,\n",
        "          content_marketplace,\n",
        "          content_language,\n",
        "          brand,\n",
        "          targetted_interest_labels,\n",
        "          brand_offerings_L1 as brand_offerings_l1,\n",
        "          brand_offerings_L2 as brand_offerings_l2,\n",
        "          marketing_creative_type,\n",
        "          marketing_category,\n",
        "          RANK() OVER (PARTITION BY thread_id, content_marketplace, content_language ORDER BY CONTENT_THREAD_VERSION DESC) AS thread_version_rank,\n",
        "          RANK() OVER (PARTITION BY THREAD_ID, CARD_KEY ORDER BY CARD_VERSION DESC) AS card_version_rank\n",
        "        from\n",
        "          content.content_dimension\n",
        "        where\n",
        "          thread_sub_type = 'thread'\n",
        "          -- and card_language in ('en', 'en-GB')\n",
        "          and not thread_id is null\n",
        "          and publish_start_date >= '{}'\n",
        "      ) thread_card\n",
        "      left join (\n",
        "        select\n",
        "          distinct card_key,\n",
        "          action_id,\n",
        "          action_text,\n",
        "          destination_type\n",
        "        from\n",
        "          cms.cms_action\n",
        "      ) action on thread_card.CARD_KEY = action.CARD_KEY\n",
        "    where\n",
        "      thread_version_rank = 1\n",
        "      and card_version_rank = 1\n",
        "    group by\n",
        "      thread_id,\n",
        "      thread_card_name,\n",
        "      content_language\n",
        "    '''.format(start_date)\n",
        "  )\n",
        "\n",
        "  airtable_tags = spark.sql(\"\"\"\n",
        "  WITH published_airtable_thread_keys AS (\n",
        "    SELECT\n",
        "      thread_key,\n",
        "      id\n",
        "    FROM\n",
        "      cms.cms_thread_external_attributes\n",
        "    WHERE\n",
        "      domain = 'control_plane'\n",
        "    GROUP BY\n",
        "      thread_key,\n",
        "      id\n",
        "  ),\n",
        "  cms_thread_keys AS (\n",
        "    SELECT DISTINCT\n",
        "      thread_key,\n",
        "      thread_id\n",
        "    FROM cms.cms_thread\n",
        "  )\n",
        "  SELECT\n",
        "    b.thread_id,\n",
        "    c.name as execution_name,\n",
        "    c.season,\n",
        "    c.primary_gender_construct,\n",
        "    c.target_gender,\n",
        "    c.primary_sport_segment,\n",
        "    c.fields_of_play\n",
        "  FROM\n",
        "    published_airtable_thread_keys a\n",
        "    JOIN cms_thread_keys b ON a.thread_key = b.thread_key\n",
        "    JOIN content_planning.plan_executions c ON a.id = c.id\n",
        "  \"\"\")\n",
        "\n",
        "  airtable_tags = (\n",
        "    airtable_tags\n",
        "    .groupBy('thread_id')\n",
        "    .agg(\n",
        "      f.max('primary_gender_construct').alias('primary_gender_construct'),\n",
        "      f.max('target_gender').alias('target_gender'),\n",
        "      f.max('primary_sport_segment').alias('primary_sport_segment'),\n",
        "      f.max('fields_of_play').alias('fields_of_play'),\n",
        "    )\n",
        "  )\n",
        "\n",
        "  thread_df = (\n",
        "    thread_df\n",
        "    .join(airtable_tags, on='thread_id', how='left')\n",
        "    .fillna(\"\", subset=['thread_card_name', 'card_title', 'card_subtitle', 'card_body'])\n",
        "    .withColumn('header', f.concat_ws(\"\\n\", f.col('thread_card_name'), f.col('card_title'), f.col('card_subtitle')))\n",
        "    .withColumn('template', f.concat_ws(\"\\n\", f.col('header'), f.col('card_body')))\n",
        "    .withColumn('template', f.trim(strip_html(f.col('template'))))\n",
        "    .withColumn('template', f.regexp_replace(f.col('template'), \"&#8232;\", \"\\n\"))\n",
        "    .withColumn('template', f.when(f.col('template') == \"\", None).otherwise(f.col('template')))\n",
        "  )\n",
        "\n",
        "  return thread_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "be3190a1-69ed-40b7-b6a9-8e65b8d84400",
          "showTitle": false,
          "title": ""
        },
        "id": "t4TEp-J3WBtH"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "thread_df = thread_text_input(start_dt)\n",
        "\n",
        "(\n",
        "  thread_df\n",
        "  .write.format('delta')\n",
        "  .mode('overwrite')\n",
        "  .option('overwriteSchema', 'True')\n",
        "  .option('url', 's3://ngap2-user-data/gck/glbl_marsci_sandbox/owned/mchu10/thread_copy_nikeapp')\n",
        "  .saveAsTable(f'mchu10.thread_copy_nikeapp')\n",
        ")\n",
        "print(f'mchu10.thread_copy_nikeapp saved')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "96cce8cc-b578-4fd1-be60-6c0602d0ca93",
          "showTitle": false,
          "title": ""
        },
        "id": "9cGRsV_0WBtH"
      },
      "outputs": [],
      "source": [
        "thread_df = spark.sql(\"SELECT * FROM mchu10.thread_copy_nikeapp\")\n",
        "print(thread_df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "347d48e5-7ca5-4a6f-a1a9-a0cce29eb190",
          "showTitle": false,
          "title": ""
        },
        "id": "y1Q9FAikWBtH"
      },
      "outputs": [],
      "source": [
        "thread_pdf = thread_df.toPandas()\n",
        "\n",
        "translator = GoogleTranslator(source='auto', target='en')\n",
        "\n",
        "def translate_to_en(txt):\n",
        "  try:\n",
        "    # time.sleep(0.3) # sleep to avoid exceeding API limit\n",
        "    translation = translator.translate(txt)\n",
        "  except:\n",
        "    translation = None\n",
        "  return translation\n",
        "\n",
        "thread_pdf['header_en'] = thread_pdf['header'].apply(translate_to_en)\n",
        "thread_pdf['template_en'] = thread_pdf['template'].apply(translate_to_en)\n",
        "\n",
        "thread_df = spark.createDataFrame(thread_pdf)\n",
        "\n",
        "\"\"\"\n",
        "(\n",
        "  thread_df\n",
        "  .write.format('delta')\n",
        "  .mode('overwrite')\n",
        "  .option('overwriteSchema', 'True')\n",
        "  .option('url', 's3://ngap2-user-data/gck/glbl_marsci_sandbox/owned/mchu10/thread_copy_nikeapp')\n",
        "  .saveAsTable(f'mchu10.thread_copy_nikeapp')\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "print(f'mchu10.thread_copy_nikeapp saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f425378d-0955-43ff-b5f9-51db8d2c7ea7",
          "showTitle": false,
          "title": ""
        },
        "id": "XVpsgPg7WBtH"
      },
      "outputs": [],
      "source": [
        "thread_df = spark.sql(\"select * from mchu10.thread_copy_nikeapp\")\n",
        "display(thread_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "51597b7b-1020-4f46-943e-c8207c9c4906",
          "showTitle": false,
          "title": ""
        },
        "id": "HI4YOI3wWBtI"
      },
      "outputs": [],
      "source": [
        "thread_df.groupBy('primary_gender_construct').count().display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "97a2438e-e3a9-4d69-87fe-70409712e183",
          "showTitle": false,
          "title": ""
        },
        "id": "N_WdeUQUWBtI"
      },
      "outputs": [],
      "source": [
        "thread_df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b4bfa19b-ad67-4c59-89ee-6ea907860cce",
          "showTitle": false,
          "title": ""
        },
        "id": "wpSNMaVeWBtI"
      },
      "source": [
        "# String Matching Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "084672f6-f2ae-48c1-bb96-e6464e7f4920",
          "showTitle": false,
          "title": ""
        },
        "id": "Urb0_1PPWBtI"
      },
      "outputs": [],
      "source": [
        "test_qa_dict = {\n",
        "  'test_qa': ['qa', 'test_', 'test lamb', 'proof test', 'proof_', 'internal seed'],\n",
        "}\n",
        "\n",
        "promo_dict = {\n",
        "  'promo': ['code', r'(?<!.pre|pre-)sale', r'\\bpromo\\b', 'promotion', 'discount',\n",
        "            'clearance', 'markdown', r'[\\d]+ off', r'[\\d]+\\$ off', r'[\\d]+% off', r'[\\d]+€ off',\n",
        "            r'[\\d]+£ off', r'[\\d]+ yen off', r'[\\d]+ yuan off', r'[\\d]+ pesos off',\n",
        "            r'save.+\\$[\\d]+', r'save.+[\\d]+\\$', r'save.+%[\\d]+', r'save.+[\\d]+%',\n",
        "            r'save.+\\€[\\d]+', r'save.+\\€[\\d]+', r'save.+\\£[\\d]+', r'save.+\\£[\\d]+',\n",
        "            r'save.+[\\d]+ yen', r'save.+[\\d]+ yuan', r'save.+[\\d]+ pesos',\n",
        "            r'deduct.+[\\d]+'],\n",
        "}\n",
        "\n",
        "other_dict = {\n",
        "  'nrc': [r'\\bnrc\\b', 'nike run club'],\n",
        "  'ntc': [r'\\bntc\\b', 'nike training club'],\n",
        "  'snkrs': [],\n",
        "  'nikebyyou': [],\n",
        "  'lifestyle': ['lifestyle'],\n",
        "  'sustainability': ['sustainab', 'green', 'climate change', 'recycle',\n",
        "                     'zero waste', 'move to zero', 'trash', 'space hippie',\n",
        "                     'earth day'],\n",
        "  'trail': [r'\\btrail\\b', r'\\bacg\\b', 'all condition'],\n",
        "  'exclusive': ['exclusive', 'first access', 'get it first'],\n",
        "  'holiday': ['holiday', 'valentine', 'galentine', \"mother's day\", 'mothers day',\n",
        "              \"father's day\", 'fathers day', 'christmas', 'boxing day', 'thanksgiving',\n",
        "              'new year', r'\\bcny\\b', 'family day'],\n",
        "  'blackfriday': ['black friday', 'cyber monday', 'cyber week'],\n",
        "  'boxingday': ['boxing day'],\n",
        "  'birthday': ['birthday', 'bday'],\n",
        "  'backtoschool': ['back to school'],\n",
        "  'memberdays': ['member days'],\n",
        "  'sneakersoftheweek': ['sneakers of the week'],\n",
        "  'newarrival': ['new arrival'],\n",
        "  'weeklyoffense': ['weekly offense'],\n",
        "  'mentalhealth': ['mental', 'meditat', 'headspace'],\n",
        "  'holisticfitness': ['holistic fitness'],\n",
        "  'trigger': [],\n",
        "  'campaign': [],\n",
        "}\n",
        "\n",
        "brand_dict = {\n",
        "  'nike': [],\n",
        "  'jordan': ['jordan', r'aj[\\d]', 'aj '],\n",
        "  'converse': ['converse'],\n",
        "  'hurley': ['hurley'],\n",
        "}\n",
        "\n",
        "construct_dict = {\n",
        "  'mens': [r'\\bmen\\b', r'\\bman\\b', '\\bmens\\b', \"\\bmen's\\b\"],\n",
        "  'womens': ['women', 'woman'],\n",
        "  'dualgender': ['dual gender', 'unisex'],\n",
        "  'kids': [],\n",
        "}\n",
        "\n",
        "sport_dict = {\n",
        "  'running': [r'(?<!.in the |time is )running(?! out of time| back| errands)', 'runner', 'marathon'],\n",
        "  'fitness': ['fitness', 'workout', r'\\bgym\\b', 'strength training', 'cardio'],\n",
        "  'globalfootball': ['football', 'soccer'],\n",
        "  'basketball': ['basketball', 'bball', 'b-ball', 'streetball', 'street ball', 'hooper'],\n",
        "  'tennis': ['tennis'],\n",
        "  'golf': ['golf'],\n",
        "  'baseball': ['baseball', 'softball'],\n",
        "  'nikesb': ['nikesb', 'nike sb', 'skateboard'],\n",
        "  'nikedance': [r'\\bdance\\b', r'\\bdancer\\b', r'\\bdancing\\b', 'ballerina'],\n",
        "  'yoga': ['yoga'],\n",
        "  'americanfootball': [],\n",
        "  'lacrosse': ['lacrosse'],\n",
        "  'trackandfield': ['track and field', 'track & field'],\n",
        "}\n",
        "\n",
        "franchise_dict = {\n",
        "  'drifitcotton': ['drifit', 'dri fit', 'dri-fit', 'df cotton'],\n",
        "  'legend': ['legend essential'],\n",
        "  'nikepro': [r'nike pro\\b'],\n",
        "  'nikeone': ['nike one'],\n",
        "  'miler': ['miler'],\n",
        "  'airforce1': ['air force 1', 'air force i', 'af1', 'af-1'],\n",
        "  'spotlight': ['spotlight hoodie'],\n",
        "  'victory': ['victory print'],\n",
        "  'flex': ['nike flex'],\n",
        "  'free': ['nike free'],\n",
        "  'tech': [r'nike tech\\b'],\n",
        "  'windrunner': ['windrunner', 'wind runner'],\n",
        "  'tempo': ['nike tempo'],\n",
        "  'therma': ['therma'],\n",
        "  'mercurial': ['mercurial'],\n",
        "  'phantom': [r'phantom(?! run)'],\n",
        "  'waffle': ['waffle'],\n",
        "  'airmax': ['airmax', 'air max', r'\\bam[\\d]', r'\\bam [\\d]'],\n",
        "  'indy': [r'\\bindy\\b'],\n",
        "  'alpha': [r'\\balpha\\b'],\n",
        "  'airjordan1': ['air jordan 1 ', 'air jordan i ', r'aj1\\b', r'aj 1\\b', r'aji\\b', r'aj i\\b'],\n",
        "  'pegasus': ['pegasus'],\n",
        "  'dunk': [r'(?<!slam )dunk'],\n",
        "  'blazer': [r'\\bblazer\\b'],\n",
        "  'revolution': ['nike revolution'],\n",
        "  'cortez': ['cortez'],\n",
        "  'metcon': ['metcon'],\n",
        "  'vapormax': ['vapormax', 'vapourmax', 'vapor max', 'vapour max', 'vapor-max', 'vapour-max'],\n",
        "  'alate': ['alate'],\n",
        "  'vomero': ['vomero'],\n",
        "  'winflo': ['winflo'],\n",
        "  'structure': ['zoom structure'],\n",
        "  'vaporfly': ['vaporfly', 'vapourfly', 'vapor fly', 'vapour fly'],\n",
        "  'cosmicunity': ['cosmic unity'],\n",
        "  'infinityrun': ['infinity run'],\n",
        "  'invinciblerun': ['invincible run', 'invincible3', 'invincible 3'],\n",
        "  'courtlegacy': ['court legacy'],\n",
        "  'courtvision': ['court vision'],\n",
        "  'huarache': ['huarache'],\n",
        "  'stadium': ['jordan stadium'],\n",
        "  'victori': [r'victori\\b'],\n",
        "  'phoenix': ['phoenix fleece'],\n",
        "  'superrep': ['superrep', 'super rep'],\n",
        "  'challenger': ['challenger'],\n",
        "  'courtroyale': ['court royale'],\n",
        "  'presto': ['presto'],\n",
        "  'zoomfly': ['zoomfly', 'zoom fly'],\n",
        "  'motiva': [r'\\bmotiva\\b'],\n",
        "}\n",
        "\n",
        "athlete_dict = {\n",
        "  # basketball\n",
        "  'michaeljordan': ['michael jordan', r'\\bmj\\b'],\n",
        "  'lebronjames': ['lebron', r'\\bbron\\b', 'lbj', 'king james'],\n",
        "  'kevindurant': ['durant', r'\\bkd\\b', 'kdx'],\n",
        "  'kobebryant': ['kobe', 'mamba'],\n",
        "  'kyrieirving': ['kyrie', 'irving', 'uncle drew'],\n",
        "  'giannis': ['giannis', 'antetokounmpo', 'zoom freak'],\n",
        "  'russellwestbrook': ['russell westbrook'],\n",
        "  'paulgeorge': [r'\\bpg\\b', 'paul george'],\n",
        "  'chrispaul': ['cp3', 'chris paul'],\n",
        "  'zionwilliamson': ['zion', 'williamson'],\n",
        "  'lukadoncic': [r'\\bluka\\b', 'doncic'],\n",
        "  'jaysontatum': ['jayson', 'tatum'],\n",
        "  'jamorant': [r'\\bja(?! wilson)', 'morant'],\n",
        "  'ruihachimura': ['rui hachimura'],\n",
        "  'pennyhardaway': ['penny hardaway'],\n",
        "  # global football\n",
        "  'cristianoronaldo': ['cristiano', 'ronaldo', 'cr7'],\n",
        "  'kylianmbappe': ['kylian', 'mbappe'],\n",
        "  'kevindebruyne': ['de bruyne', 'debruyne'],\n",
        "  'virgilvandijk': ['van dijk', 'vandijk'],\n",
        "  'adahegerberg': ['hegerberg'],\n",
        "  # american football\n",
        "  'odellbeckhamjr': ['odell beckham', r'\\bobj\\b'],\n",
        "  # tennis\n",
        "  'rafaelnadal': ['rafa', 'nadal'],\n",
        "  'rogerfederer': ['federer'],\n",
        "  'serenawilliams': ['serena.+williams'],\n",
        "  'naomiosaka': ['naomi.+osaka'],\n",
        "  'mariasharapova': ['sharapova'],\n",
        "  # golf\n",
        "  'tigerwoods': ['tiger woods'],\n",
        "  # skateboarding\n",
        "  'nyjahhuston': ['nyjah', 'huston'],\n",
        "  'ishodwair': ['ishod wair'],\n",
        "  'leobaker': ['leo baker', 'lacey baker'],\n",
        "  # running\n",
        "  'eliudkipchoge': ['eliud', 'kipchoge'],\n",
        "  # fitness\n",
        "  'mathewfraser': ['mathew fraser', 'mat fraser'],\n",
        "}\n",
        "\n",
        "division_dict = {\n",
        "  'apparel': ['apparel', 'clothing', 'clothes', 'garment'],\n",
        "  'footwear': ['footwear', 'shoe', 'sneaker', 'kicks', 'sole'],\n",
        "  'equipment': ['equipment', 'accessor'],\n",
        "}\n",
        "\n",
        "merchclass_dict = {\n",
        "  'bras': [r'\\bbra\\b', r'\\bbras\\b'],\n",
        "  'leggings': ['legging'],\n",
        "  'fleece': ['fleece'],\n",
        "  'tees': [r'\\btees\\b', 'tshirt', 't shirt', 't-shirt'],\n",
        "  'sweatshirts': ['sweatshirt'],\n",
        "  'shorts': ['shorts', 'volley short'],\n",
        "  'jerseys': [r'jersey(?! liner)'],\n",
        "  'jackets': ['jacket'],\n",
        "  'pants': [r'\\bpant\\b', 'trouser'],\n",
        "  'polos': [r'\\bpolo\\b'],\n",
        "  'tights': ['tights'],\n",
        "  'outerwear': ['outerwear'],\n",
        "  'socks': [r'sock(?!liner)'],\n",
        "  'baselayer': ['baselayer', 'base layer', 'base-layer'],\n",
        "  'midlayer': ['midlayer', 'mid layer', 'mid-layer'],\n",
        "  'skirts': ['skirt'],\n",
        "  'hoodie': ['hoodie', 'hoody'],\n",
        "  'vest': [r'\\bvest\\b'],\n",
        "  'longsleeve': ['long sleeve', 'long-sleeve'],\n",
        "  'shortsleeve': ['short sleeve', 'short-sleeve'],\n",
        "  'sleeveless': ['sleeveless', r'\\btank\\b'],\n",
        "  'scarf': ['scarf', 'scarves'],\n",
        "  'gloves': ['glove'],\n",
        "  'hat': [r'\\bhat\\b', 'beanie', '\\bcap\\b'],\n",
        "  'cleats': ['cleat'],\n",
        "  'boots': ['\\bboot\\b', '\\bboots\\b'],\n",
        "  'slides': ['slides', 'sliders', 'sandal', 'flip flops', 'flip-flops', 'slippers'],\n",
        "}\n",
        "\n",
        "league_dict = {\n",
        "  'ncaa': ['ncaa'],\n",
        "  'fiba': ['fiba'],\n",
        "  'nba': [r'\\bnba\\b'],\n",
        "  'wnba': ['wnba'],\n",
        "  'nfl': [r'\\bnfl\\b'],\n",
        "  'mlb': ['mlb'],\n",
        "  'fifa': ['fifa'],\n",
        "  'laliga': ['laliga', 'la liga'],\n",
        "  'premierleague': ['premier league'],\n",
        "  'ligue1': ['ligue1', 'ligue 1'],\n",
        "  'lalakers': ['lakers'],\n",
        "  'laclippers': ['clippers'],\n",
        "  'clevelandcavaliers': ['cavaliers'],\n",
        "  'chicagobulls': ['chicago bulls'],\n",
        "  'bostonceltics': ['celtic'],\n",
        "  'goldenstatewarriors': ['golden state', 'warriors'],\n",
        "  'barcelona': ['fc barcelona', r'f\\.c\\. barcelona', 'club barcelona', 'barcelona club'],\n",
        "  'chelsea': ['fc chelsea', r'f\\.c\\. chelsea'],\n",
        "  'manchestercity': ['manchester city', 'man city'],\n",
        "  'manchesterunited': ['manchester united', 'man united'],\n",
        "  'liverpool': ['liverpool'],\n",
        "  'tottenhamhotspur': ['tottenham', 'tottenham'],\n",
        "  'arsenal': ['arsenal', 'gunner'],\n",
        "  'intermilan': ['intermilan', 'inter milan'],\n",
        "  'parissaintgermain': ['paris saint-germain', 'paris saint germain', 'psg'],\n",
        "  'olympic': ['olympic'],\n",
        "  'grandslam': ['grand slam'],\n",
        "  'superbowl': ['super bowl'],\n",
        "  'worldcup': [],\n",
        "  'marchmadness': ['march madness', 'final four', 'elite eight', 'sweet sixteen'],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a27efac6-4f22-4e6e-a170-6d362ca24cda",
          "showTitle": false,
          "title": ""
        },
        "id": "DGuuTlknWBtR"
      },
      "outputs": [],
      "source": [
        "header_dict = {\n",
        "  'test_qa': ['airship', 'ncp', 'cp code', 'cpcd', r'(?<!la)test', 'proof'],\n",
        "  'mens': [r'\\bm\\b', r'\\bmn\\b'],\n",
        "  'womens': [r'\\bw\\b', r'\\bwo\\b', r'\\bwn\\b', r'\\bwmn\\b'],\n",
        "  'dualgender': [r'\\bdg\\b', r'\\bmw\\b', r'\\bmwk\\b', r'\\bm/w\\b'],\n",
        "  'kids': ['kid', r'\\bbg\\b', 'boy', 'girl', 'child', 'toddler', 'baby'],\n",
        "  'lifestyle': ['nsw'],\n",
        "  'globalfootball': ['gbf', 'gfb', 'ftbl'],\n",
        "  'baseball': ['baseb'],\n",
        "  'trigger': ['trigger'],\n",
        "  'campaign': ['campaign']\n",
        "}\n",
        "\n",
        "category_map = {\n",
        "  # League\n",
        "  'ncaa': ['marchmadness'],\n",
        "  'nba': ['lalakers', 'laclippers', 'clevelandcavaliers', 'chicagobulls', 'bostonceltics',\n",
        "          'goldenstatewarriors'],\n",
        "  'laliga': ['barcelona'],\n",
        "  'premierleague': ['chelsea', 'manchestercity', 'manchesterunited', 'liverpool',\n",
        "                    'tottenhamhotspur', 'arsenal'],\n",
        "  'ligue1': ['parissaintgermain'],\n",
        "  'nfl': ['superbowl'],\n",
        "  # Sport dimension\n",
        "  'running': ['miler', 'flex', 'pegasus', 'revolution', 'vomero', 'winflo', 'structure',\n",
        "              'vaporfly', 'infinityrun', 'invinciblerun', 'zoomfly', 'motiva', 'eliudkipchoge'],\n",
        "  'fitness': ['nikepro', 'nikeone', 'metcon', 'superrep', 'mathewfraser'],\n",
        "  'globalfootball': ['mercurial', 'phantom', 'cristianoronaldo', 'kylianmbappe', 'kevindebruyne',\n",
        "                     'virgilvandijk', 'adahegerberg', 'fifa', 'laliga', 'premierleague', 'ligue1',\n",
        "                     'intermilan', 'parissaintgermain', 'worldcup'],\n",
        "  'basketball': ['cosmicunity', 'michaeljordan', 'lebronjames', 'kevindurant', 'kobebryant',\n",
        "                 'kyrieirving', 'giannis', 'russellwestbrook', 'paulgeorge', 'chrispaul',\n",
        "                 'zionwilliamson', 'lukadoncic', 'jaysontatum', 'ruihachimura', 'pennyhardaway',\n",
        "                 'jamorant', 'ncaa', 'fiba', 'nba', 'wnba'],\n",
        "  'tennis': ['rafaelnadal', 'rogerfederer', 'serenawilliams', 'naomiosaka', 'mariasharapova',\n",
        "             'grandslam'],\n",
        "  'golf': ['tigerwoods'],\n",
        "  'baseball': ['mlb'],\n",
        "  'nikesb': ['nyjahhuston', 'ishodwair', 'leobaker'],\n",
        "  'americanfootball': ['nfl', 'odellbeckhamjr'],\n",
        "  # Merch class\n",
        "  'bras': ['indy', 'alate'],\n",
        "  'leggings': ['nikeone'],\n",
        "  # Division\n",
        "  'apparel': ['drifitcotton', 'miler', 'nikepro', 'phoenix', 'bras', 'leggings',\n",
        "              'fleece', 'tees', 'sweatshirts', 'shorts', 'jerseys', 'jackets',\n",
        "              'pants', 'polos', 'tights', 'outerwear', 'baselayer', 'midlayer',\n",
        "              'skirts', 'hoodie', 'vest', 'longsleeve', 'shortsleeve', 'sleeveless'],\n",
        "  'footwear': ['airforce1', 'airjordan1', 'dunk', 'airmax', 'blazer', 'pegasus', 'revolution',\n",
        "               'phantom', 'mercurial', 'legend', 'cortez', 'metcon', 'vapormax', 'vomero',\n",
        "               'winflo', 'structure', 'vaporfly', 'cosmicunity', 'infinityrun', 'invinciblerun',\n",
        "               'courtlegacy', 'courtvision', 'huarache', 'victori', 'superrep',\n",
        "               'courtroyale', 'presto', 'cleats', 'boots', 'slides'],\n",
        "  'equipment': ['socks', 'scarf', 'gloves', 'hat'],\n",
        "  # Construct\n",
        "  'womens': ['bras', 'leggings', 'skirts'],\n",
        "}\n",
        "\n",
        "tag_cat_dict = {\n",
        "  'test_qa': list(test_qa_dict.keys()),\n",
        "  'promo': list(promo_dict.keys()),\n",
        "  'other': list(other_dict.keys()),\n",
        "  'brand': list(brand_dict.keys()),\n",
        "  'franchise': list(franchise_dict.keys()),\n",
        "  'athlete': list(athlete_dict.keys()),\n",
        "  'league': list(league_dict.keys()),\n",
        "  'sport': list(sport_dict.keys()),\n",
        "  'merchclass': list(merchclass_dict.keys()),\n",
        "  'division': list(division_dict.keys()),\n",
        "  'construct': list(construct_dict.keys()),\n",
        "  'fieldsofplay': ['kids_play_all_day', 'kids_play_sport', 'womens_running', 'womens_holistic_fitness',\n",
        "                   'womens_lifestyle', 'womens_team_sports', 'mens_running', 'mens_basketball', 'mens_football',\n",
        "                   'mens_lifestyle', 'jordan_basketball', 'jordan_streetwear', 'dual_gender_running',\n",
        "                   'dual_gender_football', 'dual_gender_basketball', 'dual_gender_lifestyle']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "7dd4bee7-9ce3-4bad-8ad2-11ffe11575b5",
          "showTitle": false,
          "title": ""
        },
        "id": "1FA30cZNWBtR"
      },
      "source": [
        "# Create Automated Tagging Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4730c2c0-86eb-491a-98cf-d6693e98c1b7",
          "showTitle": false,
          "title": ""
        },
        "id": "2CmlspCXWBtS"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "def add_text_tags(df, text_col, text_dict):\n",
        "  \"\"\"\n",
        "  Adds tags by string matching on text copy.\n",
        "\n",
        "    Parameters:\n",
        "      df: pyspark dataframe\n",
        "      text_col (str): name of text copy column\n",
        "      text_dict (dict): string matching dictionary\n",
        "\n",
        "    Returns:\n",
        "      df: modified pyspark dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  # Tag comms\n",
        "  for k, v in text_dict.items():\n",
        "    tag_col = k + \"_tag\"\n",
        "    if tag_col not in df.columns:\n",
        "      if v:\n",
        "        regex_expr = \"|\".join(v)\n",
        "        regex_expr = rf\"{regex_expr}\"\n",
        "        df = (\n",
        "          df\n",
        "          .withColumn(tag_col, f.col(text_col).rlike(regex_expr))\n",
        "          .withColumn(tag_col, f.col(tag_col).cast('int'))\n",
        "        )\n",
        "      else:\n",
        "        df = df.withColumn(tag_col, f.lit(0).cast('int'))\n",
        "    else:\n",
        "      if v:\n",
        "        regex_expr = \"|\".join(v)\n",
        "        regex_expr = rf\"{regex_expr}\"\n",
        "        df = (\n",
        "          df\n",
        "          .withColumn(tag_col, (f.col(tag_col) == 1) & f.col(text_col).rlike(regex_expr))\n",
        "          .withColumn(tag_col, f.col(tag_col).cast('int'))\n",
        "        )\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "# Eventually want to re-write rest of these functions in pyspark\n",
        "def add_tags_from_metadata(df, tag_name, metadata_col, metadata_vals):\n",
        "  \"\"\"\n",
        "  Adds tags from metadata.\n",
        "\n",
        "    Parameters:\n",
        "      df: pandas dataframe\n",
        "      tag_name (str): name of tag\n",
        "      metadata_col (str): name of metadata column\n",
        "      metadata_vals (list): values in metadata column to be tagged on\n",
        "\n",
        "    Returns:\n",
        "      df: modified pandas dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  tag_col = tag_name + \"_tag\"\n",
        "  df[tag_col] = ((df[tag_col] == 1) | df[metadata_col].str.contains(\"|\".join(metadata_vals))).astype('int')\n",
        "  # df[tag_col] = ((df[tag_col] == 1) | df[metadata_col].isin(metadata_vals)).astype('int')\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def add_header_tags(df, header_dict):\n",
        "  \"\"\"\n",
        "  Adds tags by string matching on the header.\n",
        "\n",
        "    Parameters:\n",
        "      df: pandas dataframe\n",
        "      header_dict (dict): string matching dictionary\n",
        "\n",
        "    Returns:\n",
        "      df: modified pandas dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  for k, v in header_dict.items():\n",
        "    tag_col = k + \"_tag\"\n",
        "    regex_expr = \"|\".join(v)\n",
        "    regex_expr = rf\"{regex_expr}\"\n",
        "    df[tag_col] = ((df[tag_col] == 1) | (df['header'].str.contains(regex_expr))).astype('int')\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def map_tags(df, map_dict):\n",
        "  \"\"\"\n",
        "  Infers tags from word relationships/hierarchies.\n",
        "\n",
        "    Parameters:\n",
        "      df: pandas dataframe\n",
        "      map_dict (dict): dictionary describing word relationships/hierarchies\n",
        "\n",
        "    Returns\n",
        "      df: modified pandas dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  for k, v in map_dict.items():\n",
        "    tag_col = k + \"_tag\"\n",
        "    map_cols = [c + \"_tag\" for c in v]\n",
        "    map_cols.append(tag_col)\n",
        "\n",
        "    df[tag_col] = df[map_cols].sum(axis=1).clip(upper=1)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def exclude_tags(df, tags_to_toggle, tags_to_exclude):\n",
        "  \"\"\"Changes tags_to_toggle to 0 if any of tags_to_exclude is 1\"\"\"\n",
        "\n",
        "  for toggle_tag in tags_to_toggle:\n",
        "    df[toggle_tag] = ((df[toggle_tag] == 1) & (df[tags_to_exclude].sum(axis=1).clip(upper=1) == 0)).astype('int')\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def add_fields_of_play_tags(df):\n",
        "  \"\"\"Adds Fields of Play tags using construct and sport dimension tags.\"\"\"\n",
        "\n",
        "  # Fields of Play sport dimension categories\n",
        "  play_sports = ['running_tag', 'basketball_tag', 'globalfootball_tag', 'fitness_tag', 'yoga_tag', 'golf_tag',\n",
        "                 'tennis_tag', 'baseball_tag']\n",
        "  team_sports = ['basketball_tag', 'globalfootball_tag', 'golf_tag', 'tennis_tag', 'baseball_tag', 'lacrosse_tag',\n",
        "                 'trackandfield_tag']\n",
        "  holistic_fitness = ['fitness_tag', 'yoga_tag', 'holisticfitness_tag', 'bras_tag', 'leggings_tag', 'tights_tag']\n",
        "  performance = ['running_tag', 'basketball_tag', 'globalfootball_tag', 'fitness_tag', 'yoga_tag', 'golf_tag',\n",
        "                'tennis_tag', 'baseball_tag', 'lacrosse_tag', 'trackandfield_tag']\n",
        "\n",
        "  # Kids Fields of Play\n",
        "  df['kids_play_all_day_tag'] = ((df[play_sports].sum(axis=1).clip(upper=1) == 0) & (df['kids_tag'] == 1)).astype('int')\n",
        "  df['kids_play_sport_tag'] = ((df[play_sports].sum(axis=1).clip(upper=1) == 1) & (df['kids_tag'] == 1)).astype('int')\n",
        "\n",
        "  # Womens Fields of Play\n",
        "  df['womens_running_tag'] = ((df['running_tag'] == 1) & (df['womens_tag'] == 1)).astype('int')\n",
        "  df['womens_holistic_fitness_tag'] = ((df[holistic_fitness].sum(axis=1).clip(upper=1) == 1) & (df['womens_tag'] == 1)).astype('int')\n",
        "  df['womens_team_sports_tag'] = ((df[team_sports].sum(axis=1).clip(upper=1) == 1) & (df['womens_tag'] == 1)).astype('int')\n",
        "  df['womens_lifestyle_tag'] = ((df[performance].sum(axis=1).clip(upper=1) == 0) & (df['womens_tag'] == 1)).astype('int')\n",
        "\n",
        "  # Mens Fields of Play\n",
        "  df['mens_running_tag'] = ((df['running_tag'] == 1) & (df['mens_tag'] == 1)).astype('int')\n",
        "  df['mens_basketball_tag'] = ((df['basketball_tag'] == 1) & (df['mens_tag'] == 1)).astype('int')\n",
        "  df['mens_football_tag'] = ((df['globalfootball_tag'] == 1) & (df['mens_tag'] == 1)).astype('int')\n",
        "  df['mens_lifestyle_tag'] = ((df[performance].sum(axis=1).clip(upper=1) == 0) & (df['mens_tag'] == 1)).astype('int')\n",
        "\n",
        "  # Dual Gender Fields of Play\n",
        "  df['dual_gender_running_tag'] = ((df['running_tag'] == 1) & (df['dualgender_tag'] == 1)).astype('int')\n",
        "  df['dual_gender_basketball_tag'] = ((df['basketball_tag'] == 1) & (df['dualgender_tag'] == 1)).astype('int')\n",
        "  df['dual_gender_football_tag'] = ((df['globalfootball_tag'] == 1) & (df['dualgender_tag'] == 1)).astype('int')\n",
        "  df['dual_gender_lifestyle_tag'] = ((df[performance].sum(axis=1).clip(upper=1) == 0) & (df['dualgender_tag'] == 1)).astype('int')\n",
        "\n",
        "  # Jordan Fields of Play\n",
        "  df['jordan_basketball_tag'] = ((df[performance].sum(axis=1).clip(upper=1) == 1) & (df['jordan_tag'] == 1)).astype('int')\n",
        "  df['jordan_streetwear_tag'] = ((df[performance].sum(axis=1).clip(upper=1) == 0) & (df['jordan_tag'] == 1)).astype('int')\n",
        "\n",
        "  # Remove performance Fields of Play if it contains a lifestyle franchise\n",
        "  lifestyle_franchises = ['airforce1_tag', 'dunk_tag', 'airmax_tag', 'tech_tag']\n",
        "  non_lifestyle_fop = ['womens_running_tag', 'womens_holistic_fitness_tag', 'womens_team_sports_tag', 'mens_running_tag',\n",
        "                       'mens_basketball_tag', 'mens_football_tag', 'dual_gender_running_tag', 'dual_gender_football_tag']\n",
        "  df = exclude_tags(df, non_lifestyle_fop, lifestyle_franchises)\n",
        "  # Add lifestyle franchises to lifestyle Fields of Play\n",
        "  df['womens_lifestyle_tag'] = ((df[lifestyle_franchises].sum(axis=1).clip(upper=1) == 1) & (df['womens_tag'] == 1)).astype('int')\n",
        "  df['mens_lifestyle_tag'] = ((df[lifestyle_franchises].sum(axis=1).clip(upper=1) == 1) & (df['mens_tag'] == 1)).astype('int')\n",
        "  df['dual_gender_lifestyle_tag'] = ((df[lifestyle_franchises].sum(axis=1).clip(upper=1) == 1) & (df['dualgender_tag'] == 1)).astype('int')\n",
        "\n",
        "  # Remove gendered Fields of Play if Jordan\n",
        "  non_jordan_fop = ['kids_play_all_day_tag', 'kids_play_sport_tag', 'womens_running_tag', 'womens_holistic_fitness_tag',\n",
        "                    'womens_team_sports_tag', 'womens_lifestyle_tag', 'mens_running_tag', 'mens_basketball_tag',\n",
        "                    'mens_football_tag', 'mens_lifestyle_tag', 'dual_gender_running_tag', 'dual_gender_basketball_tag',\n",
        "                    'dual_gender_football_tag', 'dual_gender_lifestyle_tag']\n",
        "  df = exclude_tags(df, non_jordan_fop, ['jordan_tag'])\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def add_tag_categories(df, tag_cat_dict):\n",
        "  \"\"\"\n",
        "  Adds tag categories.\n",
        "\n",
        "    Parameters:\n",
        "      df: pandas dataframe\n",
        "      tag_cat_dict (dict): dictionary describing which tags belong in each tag category\n",
        "\n",
        "    Returns:\n",
        "      df: modified pandas dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  for k, v in tag_cat_dict.items():\n",
        "    tag_cols = [c + \"_tag\" for c in v]\n",
        "    df[k + \"_tag\"] = df[tag_cols].sum(axis=1).clip(upper=1)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def manual_overwrite(df, comm_id_list, tags_list, tag_val=1, overwrite_all=False):\n",
        "  \"\"\"\n",
        "  Manually overwrites comm_ids with specified tags.\n",
        "\n",
        "    Parameters:\n",
        "      df: pandas dataframe\n",
        "      comm_id_list (list): list of comm_ids to be overwritten\n",
        "      tag_list (list): list of tags to be overwritten\n",
        "      tag_val (int): 0 or 1, what value to overwrite tag with\n",
        "      overwrite_all (bool): if True, overwrites all other tags to 0\n",
        "\n",
        "    Returns:\n",
        "      df: modified pandas dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  df = df.set_index('comm_id')\n",
        "\n",
        "  for comm_id in comm_id_list:\n",
        "    if overwrite_all:\n",
        "      tag_cols = [c for c in df.columns if \"_tag\" in c]\n",
        "      for tag in tag_cols:\n",
        "        df.at[comm_id, tag] = 0\n",
        "\n",
        "    for tag in tags_list:\n",
        "      df.at[comm_id, tag + \"_tag\"] = tag_val\n",
        "\n",
        "  df = df.reset_index().rename(columns={'index': 'comm_id'})\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ffdb412e-7802-4ed6-8d86-27278915b6d3",
          "showTitle": false,
          "title": ""
        },
        "id": "rJ3dPUnlWBtS"
      },
      "outputs": [],
      "source": [
        "# Main function\n",
        "def create_thread_auto_tag_tbl(env='dev'):\n",
        "  \"\"\"\n",
        "  Creates and writes automated tagging table.\n",
        "\n",
        "  'dev' writes to the mchu10 schema, 'prod' writes to the glbl_marsci_sandbox schema\n",
        "  \"\"\"\n",
        "\n",
        "  thread_copy = spark.sql(\"SELECT * FROM mchu10.thread_copy_nikeapp\")\n",
        "\n",
        "  thread_copy = (\n",
        "    thread_copy\n",
        "    .withColumn('brand', f.lower(f.col('brand')))\n",
        "    .withColumn('targetted_interest_labels', f.lower(f.col('targetted_interest_labels')))\n",
        "    .withColumn('brand_offerings_l2', f.lower(f.col('brand_offerings_l2')))\n",
        "    .withColumn('marketing_category', f.lower(f.col('marketing_category')))\n",
        "    .withColumn('construct', f.lower(f.col('construct')))\n",
        "    .withColumn('construct', f.regexp_replace(f.col('construct'), \"'\", \"\"))\n",
        "    .withColumn('sport_dimension', f.lower(f.col('sport_dimension')))\n",
        "    .withColumn('field_of_play', f.lower(f.col('field_of_play')))\n",
        "    .withColumn('target_gender', f.lower(f.col('target_gender')))\n",
        "    .withColumn('target_gender', f.regexp_replace(f.col('target_gender'), \" \", \"\"))\n",
        "    .withColumn('primary_gender_construct', f.lower(f.col('primary_gender_construct')))\n",
        "    .withColumn('primary_gender_construct', f.regexp_replace(f.col('primary_gender_construct'), \" \", \"\"))\n",
        "    .withColumn('header', f.lower(f.col('header')))\n",
        "    .withColumn('template', f.lower(f.col('template')))\n",
        "    .withColumn('word_count', f.size(f.split(f.col('template'), \" \")))\n",
        "    .withColumn('construct_metadata', f.trim(f.coalesce(f.col('construct'), f.col('target_gender'), f.col('primary_gender_construct'))))\n",
        "    .withColumn('construct_metadata', f.when(f.col('construct_metadata') == \"\", None).otherwise(f.col('construct_metadata')))\n",
        "  )\n",
        "\n",
        "  # Add tags on copy\n",
        "  tag_dicts = [promo_dict, test_qa_dict, other_dict, brand_dict, construct_dict,\n",
        "               sport_dict, franchise_dict, athlete_dict, division_dict, merchclass_dict,\n",
        "               league_dict]\n",
        "  for d in tag_dicts:\n",
        "    thread_copy = add_text_tags(thread_copy, 'template', d)\n",
        "\n",
        "  thread_copy_df = thread_copy.toPandas()\n",
        "\n",
        "  # Add header tags\n",
        "  thread_copy_df = add_header_tags(thread_copy_df, header_dict)\n",
        "\n",
        "  # Add tags from metadata fields\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'jordan', 'brand', ['jordan'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'jordan', 'targetted_interest_labels', ['jordan'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'mens', 'targetted_interest_labels', [r'\\bmen\\b'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'womens', 'targetted_interest_labels', ['women'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'kids', 'targetted_interest_labels', ['boys', 'girls'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'running', 'targetted_interest_labels', ['running'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'fitness', 'targetted_interest_labels', ['training & gym'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'basketball', 'targetted_interest_labels', ['basketball'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'globalfootball', 'targetted_interest_labels', ['soccer'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'nikesb', 'targetted_interest_labels', ['skateboard'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'tennis', 'targetted_interest_labels', ['tennis'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'golf', 'targetted_interest_labels', ['golf'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'yoga', 'targetted_interest_labels', ['yoga'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'nikedance', 'targetted_interest_labels', ['dance'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'trail', 'targetted_interest_labels', ['acg'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'lifestyle', 'targetted_interest_labels', ['lifestyle'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'footwear', 'brand_offerings_l2', ['footwear'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'apparel', 'brand_offerings_l2', ['apparel'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'snkrs', 'brand_offerings_l2', ['snkrs'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'nrc', 'brand_offerings_l2', [r'\\bnrc\\b'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'ntc', 'brand_offerings_l2', [r'\\bntc\\b'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'running', 'brand_offerings_l2', ['audio guided run'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'promo', 'marketing_type', ['promo'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'jordan', 'marketing_category', ['jordan'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'mens', 'marketing_category', [r\"\\bmen's\\b\"])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'womens', 'marketing_category', [\"women's\"])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'kids', 'marketing_category', [\"kids\"])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'running', 'marketing_category', ['running'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'fitness', 'marketing_category', ['training', 'fitness'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'basketball', 'marketing_category', ['basketball'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'globalfootball', 'marketing_category', ['global football'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'nikesb', 'marketing_category', ['nike sb'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'tennis', 'marketing_category', ['tennis'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'golf', 'marketing_category', ['golf'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'americanfootball', 'marketing_category', ['american football'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'trail', 'marketing_category', ['acg'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'nikebyyou', 'marketing_category', ['nike by you'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'lifestyle', 'marketing_category', ['lifestyle', 'nsw'])\n",
        "  thread_copy_df = add_tags_from_metadata(thread_copy_df, 'holisticfitness', 'marketing_category', ['holistic fitness'])\n",
        "\n",
        "  # Infer tags from word hierarchies and relationships\n",
        "  thread_copy_df = map_tags(thread_copy_df, category_map)\n",
        "\n",
        "  # Logic for brand\n",
        "  # Tag any comms without a brand as nike\n",
        "  thread_copy_df['nike_tag'] = ((thread_copy_df['jordan_tag'] == 0) & (thread_copy_df['converse_tag'] == 0) & (thread_copy_df['hurley_tag'] == 0)).astype('int')\n",
        "\n",
        "  # Logic for construct\n",
        "  # If comm has both mens and womens tag -> tag as dual gender and remove mens and womens tag\n",
        "  thread_copy_df['dualgender_tag'] = ((thread_copy_df['dualgender_tag'] == 1) | ((thread_copy_df['mens_tag'] == 1) & (thread_copy_df['womens_tag'] == 1))).astype('int')\n",
        "  thread_copy_df['mens_tag'] = ((thread_copy_df['mens_tag'] == 1) & (thread_copy_df['dualgender_tag'] == 0)).astype('int')\n",
        "  thread_copy_df['womens_tag'] = ((thread_copy_df['womens_tag'] == 1) & (thread_copy_df['dualgender_tag'] == 0)).astype('int')\n",
        "  # Remove mens, womens, and dual gender tag if tagged as kids\n",
        "  thread_copy_df['womens_tag'] = ((thread_copy_df['womens_tag'] == 1) & (thread_copy_df['kids_tag'] != 1)).astype('int')\n",
        "  thread_copy_df['mens_tag'] = ((thread_copy_df['mens_tag'] == 1) & (thread_copy_df['kids_tag'] != 1)).astype('int')\n",
        "  thread_copy_df['dualgender_tag'] = ((thread_copy_df['dualgender_tag'] == 1) & (thread_copy_df['kids_tag'] != 1)).astype('int')\n",
        "  # Overwrite construct with already tagged columns\n",
        "  thread_copy_df['mens_tag'] = thread_copy_df.apply(lambda row: 0 if row['construct_metadata'] is not None else row['mens_tag'], axis=1)\n",
        "  thread_copy_df['womens_tag'] = thread_copy_df.apply(lambda row: 0 if row['construct_metadata'] is not None else row['womens_tag'], axis=1)\n",
        "  thread_copy_df['dualgender_tag'] = thread_copy_df.apply(lambda row: 0 if row['construct_metadata'] is not None else row['dualgender_tag'], axis=1)\n",
        "  thread_copy_df['kids_tag'] = thread_copy_df.apply(lambda row: 0 if row['construct_metadata'] is not None else row['kids_tag'], axis=1)\n",
        "  thread_copy_df['mens_tag'] = ((thread_copy_df['mens_tag'] == 1) | (thread_copy_df['construct_metadata'] == \"mens\")).astype('int')\n",
        "  thread_copy_df['womens_tag'] = ((thread_copy_df['womens_tag'] == 1) | (thread_copy_df['construct_metadata'] == \"womens\")).astype('int')\n",
        "  thread_copy_df['dualgender_tag'] = ((thread_copy_df['dualgender_tag'] == 1) | (thread_copy_df['construct_metadata'] == \"dualgender\")).astype('int')\n",
        "  thread_copy_df['kids_tag'] = ((thread_copy_df['kids_tag'] == 1) | (thread_copy_df['construct_metadata'] == \"kids\")).astype('int')\n",
        "  thread_copy_df = thread_copy_df.drop(columns=['construct_metadata'])\n",
        "\n",
        "  # Add Fields of Play tags and tag categories\n",
        "  thread_copy_df = add_fields_of_play_tags(thread_copy_df)\n",
        "  thread_copy_df = add_tag_categories(thread_copy_df, tag_cat_dict)\n",
        "\n",
        "  # Manual overwrite\n",
        "\n",
        "  # Exclude tags\n",
        "  thread_copy_df = exclude_tags(thread_copy_df, ['globalfootball_tag'], ['americanfootball_tag'])\n",
        "  thread_copy_df = exclude_tags(thread_copy_df, ['kids_play_all_day_tag', 'mens_lifestyle_tag', 'womens_lifestyle_tag'], ['birthday_tag'])\n",
        "\n",
        "  # Add tagged column for at least one tag for coverage calculation\n",
        "  tag_cols = [c for c in thread_copy_df.columns if \"_tag\" in c]\n",
        "  thread_copy_df['tagged'] = thread_copy_df[tag_cols].sum(axis=1).clip(upper=1)\n",
        "\n",
        "  thread_copy = spark.createDataFrame(thread_copy_df)\n",
        "  tag_cols.append('tagged')\n",
        "  thread_copy = thread_copy.fillna(0, subset=tag_cols)\n",
        "\n",
        "  tbl_name = \"thread_nikeapp_automated_tags\"\n",
        "\n",
        "\"\"\"\n",
        "  if env == 'prod':\n",
        "    (\n",
        "      thread_copy\n",
        "      .write.format('delta')\n",
        "      .mode('overwrite')\n",
        "      .option('overwriteSchema', 'True')\n",
        "      .option('url', f's3://ngap--glbl-marsci--prod--us-east-1/Owned-Media/{tbl_name}')\n",
        "      .saveAsTable(f'glbl_marsci_sandbox.{tbl_name}')\n",
        "    )\n",
        "    print(f\"glbl_marsci_sandbox.{tbl_name} created\")\n",
        "  elif env == 'dev':\n",
        "    (\n",
        "      thread_copy\n",
        "      .write.format('delta')\n",
        "      .mode('overwrite')\n",
        "      .option('overwriteSchema', 'True')\n",
        "      .option('url', f's3://ngap2-user-data/gck/glbl_marsci_sandbox/owned/mchu10/{tbl_name}')\n",
        "      .saveAsTable(f'mchu10.{tbl_name}')\n",
        "    )\n",
        "    print(f\"mchu10.{tbl_name} created\")\n",
        "  else:\n",
        "    raise Exception(\"Specify env = 'dev' or 'prod'\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c01d49f4-5289-4d5c-a894-41f39ba2183f",
          "showTitle": false,
          "title": ""
        },
        "id": "SCM0BiZXWBtT"
      },
      "outputs": [],
      "source": [
        "create_thread_auto_tag_tbl(env='dev')\n",
        "create_thread_auto_tag_tbl(env='prod')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f252546e-03e7-437a-a7db-ba647e3298f1",
          "showTitle": false,
          "title": ""
        },
        "id": "MgC5-Pg7WBtT"
      },
      "outputs": [],
      "source": [
        "auto_tag = spark.sql(\"SELECT * FROM glbl_marsci_sandbox.thread_nikeapp_automated_tags\")\n",
        "auto_tag_df = auto_tag.toPandas()\n",
        "display(auto_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "98b585a1-fb2d-4bb5-832d-ee2cf42f9197",
          "showTitle": false,
          "title": ""
        },
        "id": "fdhUFyc_WBtT"
      },
      "outputs": [],
      "source": [
        "def transform_bool_to_list(df, tag_cat_dict):\n",
        "  \"\"\"\n",
        "  Transforms automated tagging boolean columns into comma-separated string\n",
        "  under tag categories.\n",
        "\n",
        "    Parameters:\n",
        "      df: pandas dataframe\n",
        "      tag_cat_dict (dict): dictionary describing which tags belong in each tag category\n",
        "\n",
        "    Returns:\n",
        "      df: modified pandas dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  keep_cols = ['thread_id', 'thread_card_name', 'card_title', 'card_subtitle', 'card_body', 'action_text',\n",
        "               'action_destination_type', 'brand', 'targetted_interest_labels', 'brand_offerings_l1',\n",
        "               'brand_offerings_l2', 'marketing_type', 'marketing_category', 'sport_dimension', 'construct',\n",
        "               'field_of_play', 'primary_gender_construct', 'target_gender', 'primary_sport_segment',\n",
        "               'fields_of_play', 'header', 'template', 'word_count']\n",
        "  list_df = df[keep_cols].copy()\n",
        "\n",
        "  for k, v in tag_cat_dict.items():\n",
        "    tag_cols = [c + \"_tag\" for c in v]\n",
        "    tag_cat_df = df[tag_cols]\n",
        "    list_df[k + \"_tag_list\"] = tag_cat_df.eq(1).dot(tag_cat_df.columns + \",\").str.rstrip(\",\").str.replace(\"_tag\", \"\")\n",
        "\n",
        "  list_df = list_df.replace(r'^\\s*$', np.nan, regex=True)\n",
        "\n",
        "  return list_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "24c1c5d9-2296-458b-bc36-e34471157ca4",
          "showTitle": false,
          "title": ""
        },
        "id": "GkSvNtSAWBtU"
      },
      "outputs": [],
      "source": [
        "auto_tag_list = transform_bool_to_list(auto_tag_df, tag_cat_dict)\n",
        "\n",
        "auto_tag_list = spark.createDataFrame(auto_tag_list)\n",
        "\n",
        "auto_tag_list = (\n",
        "  auto_tag_list\n",
        "  # .withColumn(\n",
        "  #   'construct_tag_list',\n",
        "  #   f.when(f.col('construct_tag_list').contains(\",\"), f.lit(\"multiple_construct\")).otherwise(f.col('construct_tag_list'))\n",
        "  # )\n",
        "  .withColumn(\n",
        "    'fieldsofplay_tag_list',\n",
        "    f.when(f.col('fieldsofplay_tag_list').contains(\",\"), f.concat(f.col('construct_tag_list'), f.lit(\"_multiple_fop\"))).otherwise(f.col('fieldsofplay_tag_list'))\n",
        "  ).withColumn(\n",
        "    'division_tag_list',\n",
        "    f.when(f.col('division_tag_list').contains(\",\"), f.lit(\"multiple_division\")).otherwise(f.col('division_tag_list'))\n",
        "  ).withColumn(\n",
        "    'merchclass_tag_list',\n",
        "    f.when(f.col('merchclass_tag_list').contains(\",\"), f.lit(\"multiple_merchclass\")).otherwise(f.col('merchclass_tag_list'))\n",
        "  ).withColumn(\n",
        "    'sport_tag_list',\n",
        "    f.when(f.col('sport_tag_list').contains(\",\"), f.lit(\"multiple_sport\")).otherwise(f.col('sport_tag_list'))\n",
        "  ).withColumn(\n",
        "    'league_tag_list',\n",
        "    f.when(f.col('league_tag_list').contains(\",\"), f.lit(\"multiple_league\")).otherwise(f.col('league_tag_list'))\n",
        "  ).withColumn(\n",
        "    'athlete_tag_list',\n",
        "    f.when(f.col('athlete_tag_list').contains(\",\"), f.lit(\"multiple_athlete\")).otherwise(f.col('athlete_tag_list'))\n",
        "  ).withColumn(\n",
        "    'franchise_tag_list',\n",
        "    f.when(f.col('franchise_tag_list').contains(\",\"), f.lit(\"multiple_franchise\")).otherwise(f.col('franchise_tag_list'))\n",
        "  )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "63d91996-5fa3-401e-a00a-866b4f5380de",
          "showTitle": false,
          "title": ""
        },
        "id": "xIG4rRHKWBtU"
      },
      "outputs": [],
      "source": [
        "tbl_name = \"thread_nikeapp_automated_tags_list\"\n",
        "\n",
        "\"\"\"\n",
        "(\n",
        "  auto_tag_list\n",
        "  .write.format('delta')\n",
        "  .mode('overwrite')\n",
        "  .option('overwriteSchema', 'True')\n",
        "  .option('url', f's3://ngap2-user-data/gck/glbl_marsci_sandbox/owned/mchu10/{tbl_name}')\n",
        "  .saveAsTable(f'mchu10.{tbl_name}')\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5426ac47-6116-4239-8416-66f6921f3cab",
          "showTitle": false,
          "title": ""
        },
        "id": "hESfAaPtWBtU"
      },
      "outputs": [],
      "source": [
        "tbl_name = \"thread_nikeapp_automated_tags_list\"\n",
        "\n",
        "\"\"\"\n",
        "(\n",
        "  auto_tag_list\n",
        "  .write.format('delta')\n",
        "  .mode('overwrite')\n",
        "  .option('overwriteSchema', 'True')\n",
        "  .option('url', f's3://ngap--glbl-marsci--prod--us-east-1/Owned-Media/{tbl_name}')\n",
        "  .saveAsTable(f'glbl_marsci_sandbox.{tbl_name}')\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c341fef4-db4f-48e4-8470-b0aff9024082",
          "showTitle": false,
          "title": ""
        },
        "id": "y9CiIC3xWBtU"
      },
      "outputs": [],
      "source": [
        "auto_tag_list = spark.sql(\"SELECT * FROM glbl_marsci_sandbox.thread_nikeapp_automated_tags_list\")\n",
        "display(auto_tag_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f1976336-40c1-40c3-b342-fe38c8495f0d",
          "showTitle": false,
          "title": ""
        },
        "id": "QD6L_HP5WBtU"
      },
      "outputs": [],
      "source": [
        "auto_tag_list.filter(f.col('construct_tag_list').contains(\",\")).display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f8c3d929-f096-47f3-94dc-3025c8cac1dd",
          "showTitle": false,
          "title": ""
        },
        "id": "VzzQkgAiWBtV"
      },
      "outputs": [],
      "source": [
        "sample_sdf = auto_tag_list.filter(f.col('construct_tag_list').isNotNull())\n",
        "frac = 52 / sample_sdf.count()\n",
        "print(sample_sdf.count())\n",
        "print(frac)\n",
        "sample_sdf.sample(fraction=frac).display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b7a62c65-4c44-4cd9-9820-718a88ae4074",
          "showTitle": false,
          "title": ""
        },
        "id": "JBWy7nueWBtV"
      },
      "source": [
        "# Coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1421f8f2-5118-42e1-88b2-12ac65630c25",
          "showTitle": false,
          "title": ""
        },
        "id": "i0wdoyhZWBtV"
      },
      "outputs": [],
      "source": [
        "print(f\"Total # of Comms: {auto_tag_df.shape[0]}\")\n",
        "print(f\"Total # of Comms with non-null text copy: {auto_tag_df[auto_tag_df['template'].notnull()].shape[0]}\")\n",
        "print(f\"Total # of Comms (test/qa removed): {auto_tag_df[auto_tag_df['test_qa_tag'] != 1].shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6558b8a9-6411-499d-acab-38984ec4884a",
          "showTitle": false,
          "title": ""
        },
        "id": "WNTAQT_eWBtV"
      },
      "outputs": [],
      "source": [
        "drop_cols = ['thread_id', 'thread_card_name', 'card_title', 'card_subtitle', 'card_body', 'action_text',\n",
        "            'action_destination_type', 'brand', 'targetted_interest_labels', 'brand_offerings_l1',\n",
        "            'brand_offerings_l2', 'marketing_type', 'marketing_category', 'sport_dimension', 'construct',\n",
        "            'field_of_play', 'primary_gender_construct', 'target_gender', 'primary_sport_segment',\n",
        "            'fields_of_play', 'header', 'template', 'word_count']\n",
        "\n",
        "tag_freq = (\n",
        "  auto_tag_df\n",
        "  .drop(columns=drop_cols)\n",
        "  .sum(axis=0)\n",
        "  .reset_index()\n",
        ")\n",
        "tag_freq.columns = ['tag', 'count']\n",
        "tag_freq['tag'] = tag_freq['tag'].str.replace(\"_tag\", \"\")\n",
        "tag_freq['perc'] = (tag_freq['count'] / auto_tag_df.shape[0]) * 100\n",
        "display(tag_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "02935208-a8ef-4e82-acb8-d16267f6dd1f",
          "showTitle": false,
          "title": ""
        },
        "id": "iHdnOowRWBtV"
      },
      "outputs": [],
      "source": [
        "drop_cols = list(tag_freq[tag_freq['count'] == 0]['tag'].values)\n",
        "drop_cols = [c + \"_tag\" for c in drop_cols]\n",
        "print(drop_cols)\n",
        "auto_tag_df = auto_tag_df.drop(columns=drop_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0d289a54-b68e-4e9d-943c-306050afa699",
          "showTitle": false,
          "title": ""
        },
        "id": "rJLib3LYWBtW"
      },
      "outputs": [],
      "source": [
        "plot_df = tag_freq[tag_freq['tag'].isin(tag_cat_dict['construct'])]\n",
        "plot_df = plot_df.sort_values('count', ascending=False).head(15)\n",
        "\n",
        "fig = px.bar(\n",
        "  plot_df, x='tag', y='perc',\n",
        "  text='perc', template='plotly_white',\n",
        "  title='<b>Construct Tags Coverage</b>',\n",
        "  labels={\n",
        "    'tag': 'Tag',\n",
        "    'perc': 'Comms %'\n",
        "  },\n",
        "  height=600, width=800\n",
        ")\n",
        "\n",
        "fig.update_traces(texttemplate='<b>%%{text: .1f}</b>')\n",
        "fig.update_layout(font_size=16)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "19ede624-ffd0-436f-a81b-a3a58edde00d",
          "showTitle": false,
          "title": ""
        },
        "id": "k5txRoyxWBtW"
      },
      "outputs": [],
      "source": [
        "plot_df = tag_freq[tag_freq['tag'].isin(list(tag_cat_dict.keys()))]\n",
        "plot_df = plot_df.sort_values('count', ascending=False).head(15)\n",
        "\n",
        "fig = px.bar(\n",
        "  plot_df, x='tag', y='perc',\n",
        "  text='perc', template='plotly_white',\n",
        "  title='<b>Tag Category Coverage</b>',\n",
        "  labels={\n",
        "    'tag': 'Tag Category',\n",
        "    'perc': 'Comms %'\n",
        "  },\n",
        "  height=600, width=800\n",
        ")\n",
        "\n",
        "fig.update_traces(texttemplate='<b>%%{text: .0f}</b>')\n",
        "fig.update_layout(font_size=16)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e1e2cb49-95b6-4201-b135-6411c3fdfe01",
          "showTitle": false,
          "title": ""
        },
        "id": "yQz0MnLpWBtW"
      },
      "source": [
        "# QA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "implicitDf": true,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2ec98e7c-96d0-4f87-a4f1-689929bef425",
          "showTitle": false,
          "title": ""
        },
        "id": "3bj_TC6OWBtW"
      },
      "outputs": [],
      "source": [
        "%sql\n",
        "select * from content_planning.plan_executions where cardinality(fields_of_play) != 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "356cf28f-fe4e-4635-ae00-4b5531e0c9d5",
          "showTitle": false,
          "title": ""
        },
        "id": "DO3AHEbxWBtW"
      },
      "outputs": [],
      "source": [
        "airtable_tags = spark.sql(\"\"\"\n",
        "WITH published_airtable_thread_keys AS (\n",
        "  SELECT\n",
        "    thread_key,\n",
        "    id\n",
        "  FROM\n",
        "    cms.cms_thread_external_attributes\n",
        "  WHERE\n",
        "    domain = 'control_plane'\n",
        "  GROUP BY\n",
        "    thread_key,\n",
        "    id\n",
        "),\n",
        "cms_thread_keys AS (\n",
        "  SELECT DISTINCT\n",
        "    thread_key,\n",
        "    thread_id\n",
        "  FROM cms.cms_thread\n",
        ")\n",
        "SELECT\n",
        "  b.thread_id,\n",
        "  c.name as execution_name,\n",
        "  c.season,\n",
        "  c.primary_gender_construct,\n",
        "  c.target_gender,\n",
        "  c.primary_sport_segment,\n",
        "  c.fields_of_play\n",
        "FROM\n",
        "  published_airtable_thread_keys a\n",
        "  JOIN cms_thread_keys b ON a.thread_key = b.thread_key\n",
        "  JOIN content_planning.plan_executions c ON a.id = c.id\n",
        "\"\"\")\n",
        "\n",
        "airtable_tags = (\n",
        "  airtable_tags\n",
        "  .groupBy('thread_id')\n",
        "  .agg(\n",
        "    f.max('primary_gender_construct').alias('primary_gender_construct'),\n",
        "    f.max('target_gender').alias('target_gender'),\n",
        "    f.max('primary_sport_segment').alias('primary_sport_segment'),\n",
        "    f.max('fields_of_play').alias('fields_of_play'),\n",
        "  )\n",
        ")\n",
        "\n",
        "display(airtable_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b1a8bb00-1b44-4c1b-93d6-55348ad00006",
          "showTitle": false,
          "title": ""
        },
        "id": "JwQp2p0yWBtW"
      },
      "outputs": [],
      "source": [
        "tag_comp_df = auto_tag_list.toPandas()\n",
        "display(tag_comp_df)\n",
        "\n",
        "print(\"Non-null construct: {}\".format(tag_comp_df['construct'].notnull().sum()))\n",
        "print(\"Non-null primary_gender_construct: {}\".format(tag_comp_df['primary_gender_construct'].notnull().sum()))\n",
        "print(\"Non-null target_gender: {}\".format(tag_comp_df['target_gender'].notnull().sum()))\n",
        "\n",
        "tag_comp_df['primary_gender_construct'] = tag_comp_df['primary_gender_construct'].str.lower().str.replace(\" \", \"\")\n",
        "tag_comp_df['target_gender'] = tag_comp_df['target_gender'].str.lower().str.replace(\" \", \"\")\n",
        "\n",
        "print(f\"Number of threads where primary_gender_construct equals target_gender: {(tag_comp_df['primary_gender_construct'] == tag_comp_df['target_gender']).astype(int).sum()}\")\n",
        "print(f\"Number of threads where construct tag equals target_gender: {(tag_comp_df['construct_tag_list'] == tag_comp_df['target_gender']).astype(int).sum()}\")\n",
        "print(f\"Number of threads where construct tag equals construct: {(tag_comp_df['construct_tag_list'] == tag_comp_df['construct']).astype(int).sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7dcdb2f4-73a2-40ce-8486-ac413703d4ba",
          "showTitle": false,
          "title": ""
        },
        "id": "_mY_ybcJWBtX"
      },
      "outputs": [],
      "source": [
        "auto_tag_list_df = auto_tag_list.toPandas()\n",
        "auto_tag_list_df['construct'] = auto_tag_list_df['construct'].str.replace(\"'\", \"\")\n",
        "auto_tag_list_df['sport_dimension'] = auto_tag_list_df['sport_dimension'].str.replace(\" \", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7af9a4b5-fca0-4eef-ba3c-fef67f2222cc",
          "showTitle": false,
          "title": ""
        },
        "id": "VuZSg011WBtc"
      },
      "outputs": [],
      "source": [
        "auto_tag_list_df['construct_tag_list'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a21ea548-6a1b-43bb-864b-47db2bbd9297",
          "showTitle": false,
          "title": ""
        },
        "id": "OMgaGWQiWBtc"
      },
      "outputs": [],
      "source": [
        "auto_tag_list_df['construct'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3378bdfd-a02e-4347-8ed5-75b2e10009e3",
          "showTitle": false,
          "title": ""
        },
        "id": "zUC6u5XYWBtd"
      },
      "outputs": [],
      "source": [
        "auto_tag_list_df['sport_tag_list'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f63f6015-f072-46a6-a56e-c15aca656154",
          "showTitle": false,
          "title": ""
        },
        "id": "OcF2Yu5nWBtd"
      },
      "outputs": [],
      "source": [
        "auto_tag_list_df['sport_dimension'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0ab1d70f-921a-42cf-90a9-712d2499e5ca",
          "showTitle": false,
          "title": ""
        },
        "id": "OMmN61AcWBtd"
      },
      "outputs": [],
      "source": [
        "eval_df = auto_tag_list_df[auto_tag_list_df['construct'].notnull()].copy()\n",
        "eval_df['correct'] = (eval_df['construct_tag_list'] == eval_df['construct']).astype(int)\n",
        "print(\"'construct' accuracy (vs. CMS labels): {}\".format(eval_df['correct'].sum() / eval_df.shape[0]))\n",
        "\n",
        "values = list(set(eval_df['construct']))\n",
        "precision = []\n",
        "recall = []\n",
        "for value in values:\n",
        "  precision.append(precision_score(eval_df['construct'], eval_df['construct_tag_list'], labels=[value], average=None, zero_division=0)[0])\n",
        "  recall.append(recall_score(eval_df['construct'], eval_df['construct_tag_list'], labels=[value], average=None, zero_division=0)[0])\n",
        "metrics_df = pd.DataFrame({\n",
        "  'actual': values,\n",
        "  'precision': precision,\n",
        "  'recall': recall\n",
        "})\n",
        "display(metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "da5824ea-efff-408e-a191-2a860d410125",
          "showTitle": false,
          "title": ""
        },
        "id": "UoBqo1T7WBtd"
      },
      "outputs": [],
      "source": [
        "eval_df = auto_tag_list_df[(auto_tag_list_df['sport_dimension'].notnull()) & (auto_tag_list_df['sport_dimension'] != 'nikebyyou')].copy()\n",
        "eval_df['correct'] = (eval_df['sport_tag_list'] == eval_df['sport_dimension']).astype(int)\n",
        "print(\"'sport dimension' accuracy: {}\".format(eval_df['correct'].sum() / eval_df.shape[0]))\n",
        "\n",
        "values = list(set(eval_df['sport_dimension']))\n",
        "precision = []\n",
        "recall = []\n",
        "for value in values:\n",
        "  precision.append(precision_score(eval_df['sport_dimension'], eval_df['sport_tag_list'], labels=[value], average=None, zero_division=0)[0])\n",
        "  recall.append(recall_score(eval_df['sport_dimension'], eval_df['sport_tag_list'], labels=[value], average=None, zero_division=0)[0])\n",
        "metrics_df = pd.DataFrame({\n",
        "  'actual': values,\n",
        "  'precision': precision,\n",
        "  'recall': recall\n",
        "})\n",
        "display(metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6c43cf5e-dbb7-49f1-aa47-563e12048b43",
          "showTitle": false,
          "title": ""
        },
        "id": "Kb0gthOJWBtd"
      },
      "outputs": [],
      "source": [
        "# Auto Tag Table without metadata\n",
        "def create_thread_auto_tag_tbl(env='dev'):\n",
        "  \"\"\"\n",
        "  Creates and writes automated tagging table.\n",
        "\n",
        "  'dev' writes to the mchu10 schema, 'prod' writes to the glbl_marsci_sandbox schema\n",
        "  \"\"\"\n",
        "\n",
        "  thread_copy = spark.sql(\"SELECT * FROM mchu10.thread_copy_nikeapp\")\n",
        "\n",
        "  thread_copy = (\n",
        "    thread_copy\n",
        "    .withColumn('brand', f.lower(f.col('brand')))\n",
        "    .withColumn('targetted_interest_labels', f.lower(f.col('targetted_interest_labels')))\n",
        "    .withColumn('brand_offerings_l2', f.lower(f.col('brand_offerings_l2')))\n",
        "    .withColumn('marketing_category', f.lower(f.col('marketing_category')))\n",
        "    .withColumn('construct', f.lower(f.col('construct')))\n",
        "    .withColumn('construct', f.regexp_replace(f.col('construct'), \"'\", \"\"))\n",
        "    .withColumn('sport_dimension', f.lower(f.col('sport_dimension')))\n",
        "    .withColumn('field_of_play', f.lower(f.col('field_of_play')))\n",
        "    .withColumn('target_gender', f.lower(f.col('target_gender')))\n",
        "    .withColumn('target_gender', f.regexp_replace(f.col('target_gender'), \" \", \"\"))\n",
        "    .withColumn('primary_gender_construct', f.lower(f.col('primary_gender_construct')))\n",
        "    .withColumn('primary_gender_construct', f.regexp_replace(f.col('primary_gender_construct'), \" \", \"\"))\n",
        "    .withColumn('header', f.lower(f.col('header')))\n",
        "    .withColumn('template', f.lower(f.col('template')))\n",
        "    .withColumn('word_count', f.size(f.split(f.col('template'), \" \")))\n",
        "    .withColumn('construct_metadata', f.trim(f.coalesce(f.col('construct'), f.col('target_gender'), f.col('primary_gender_construct'))))\n",
        "    .withColumn('construct_metadata', f.when(f.col('construct_metadata') == \"\", None).otherwise(f.col('construct_metadata')))\n",
        "  )\n",
        "\n",
        "  # Add tags on copy\n",
        "  tag_dicts = [promo_dict, test_qa_dict, other_dict, brand_dict, construct_dict,\n",
        "               sport_dict, franchise_dict, athlete_dict, division_dict, merchclass_dict,\n",
        "               league_dict]\n",
        "  for d in tag_dicts:\n",
        "    thread_copy = add_text_tags(thread_copy, 'template', d)\n",
        "\n",
        "  thread_copy_df = thread_copy.toPandas()\n",
        "\n",
        "  # Add header tags\n",
        "  thread_copy_df = add_header_tags(thread_copy_df, header_dict)\n",
        "\n",
        "  # Infer tags from word hierarchies and relationships\n",
        "  thread_copy_df = map_tags(thread_copy_df, category_map)\n",
        "\n",
        "  # Logic for brand\n",
        "  # Tag any comms without a brand as nike\n",
        "  thread_copy_df['nike_tag'] = ((thread_copy_df['jordan_tag'] == 0) & (thread_copy_df['converse_tag'] == 0) & (thread_copy_df['hurley_tag'] == 0)).astype('int')\n",
        "\n",
        "  # Logic for construct\n",
        "  # If comm has both mens and womens tag -> tag as dual gender and remove mens and womens tag\n",
        "  thread_copy_df['dualgender_tag'] = ((thread_copy_df['dualgender_tag'] == 1) | ((thread_copy_df['mens_tag'] == 1) & (thread_copy_df['womens_tag'] == 1))).astype('int')\n",
        "  thread_copy_df['mens_tag'] = ((thread_copy_df['mens_tag'] == 1) & (thread_copy_df['dualgender_tag'] == 0)).astype('int')\n",
        "  thread_copy_df['womens_tag'] = ((thread_copy_df['womens_tag'] == 1) & (thread_copy_df['dualgender_tag'] == 0)).astype('int')\n",
        "  # Remove mens, womens, and dual gender tag if tagged as kids\n",
        "  thread_copy_df['womens_tag'] = ((thread_copy_df['womens_tag'] == 1) & (thread_copy_df['kids_tag'] != 1)).astype('int')\n",
        "  thread_copy_df['mens_tag'] = ((thread_copy_df['mens_tag'] == 1) & (thread_copy_df['kids_tag'] != 1)).astype('int')\n",
        "  thread_copy_df['dualgender_tag'] = ((thread_copy_df['dualgender_tag'] == 1) & (thread_copy_df['kids_tag'] != 1)).astype('int')\n",
        "  thread_copy_df = thread_copy_df.drop(columns=['construct_metadata'])\n",
        "\n",
        "  # Add Fields of Play tags and tag categories\n",
        "  thread_copy_df = add_fields_of_play_tags(thread_copy_df)\n",
        "  thread_copy_df = add_tag_categories(thread_copy_df, tag_cat_dict)\n",
        "\n",
        "  # Manual overwrite\n",
        "\n",
        "  # Exclude tags\n",
        "  thread_copy_df = exclude_tags(thread_copy_df, ['globalfootball_tag'], ['americanfootball_tag'])\n",
        "  thread_copy_df = exclude_tags(thread_copy_df, ['kids_play_all_day_tag', 'mens_lifestyle_tag', 'womens_lifestyle_tag'], ['birthday_tag'])\n",
        "\n",
        "  # Add tagged column for at least one tag for coverage calculation\n",
        "  tag_cols = [c for c in thread_copy_df.columns if \"_tag\" in c]\n",
        "  thread_copy_df['tagged'] = thread_copy_df[tag_cols].sum(axis=1).clip(upper=1)\n",
        "\n",
        "  thread_copy = spark.createDataFrame(thread_copy_df)\n",
        "  tag_cols.append('tagged')\n",
        "  thread_copy = thread_copy.fillna(0, subset=tag_cols)\n",
        "\n",
        "  tbl_name = \"thread_nikeapp_automated_tags_no_metadata\"\n",
        "\n",
        "\"\"\"\n",
        "  if env == 'prod':\n",
        "    (\n",
        "      thread_copy\n",
        "      .write.format('delta')\n",
        "      .mode('overwrite')\n",
        "      .option('overwriteSchema', 'True')\n",
        "      .option('url', f's3://ngap--glbl-marsci--prod--us-east-1/Owned-Media/{tbl_name}')\n",
        "      .saveAsTable(f'glbl_marsci_sandbox.{tbl_name}')\n",
        "    )\n",
        "    print(f\"glbl_marsci_sandbox.{tbl_name} created\")\n",
        "  elif env == 'dev':\n",
        "    (\n",
        "      thread_copy\n",
        "      .write.format('delta')\n",
        "      .mode('overwrite')\n",
        "      .option('overwriteSchema', 'True')\n",
        "      .option('url', f's3://ngap2-user-data/gck/glbl_marsci_sandbox/owned/mchu10/{tbl_name}')\n",
        "      .saveAsTable(f'mchu10.{tbl_name}')\n",
        "    )\n",
        "    print(f\"mchu10.{tbl_name} created\")\n",
        "  else:\n",
        "    raise Exception(\"Specify env = 'dev' or 'prod'\")\n",
        "\n",
        "create_thread_auto_tag_tbl(env='dev')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0d04fa7a-f752-48bc-b67d-f645f6c2fea8",
          "showTitle": false,
          "title": ""
        },
        "id": "_n9f5UNYWBte"
      },
      "outputs": [],
      "source": [
        "auto_tag = spark.sql(\"SELECT * FROM mchu10.thread_nikeapp_automated_tags_no_metadata\")\n",
        "auto_tag_df = auto_tag.toPandas()\n",
        "\n",
        "auto_tag_list = transform_bool_to_list(auto_tag_df, tag_cat_dict)\n",
        "\n",
        "auto_tag_list = spark.createDataFrame(auto_tag_list)\n",
        "\n",
        "auto_tag_list = (\n",
        "  auto_tag_list\n",
        "  # .withColumn(\n",
        "  #   'construct_tag_list',\n",
        "  #   f.when(f.col('construct_tag_list').contains(\",\"), f.lit(\"multiple_construct\")).otherwise(f.col('construct_tag_list'))\n",
        "  # )\n",
        "  .withColumn(\n",
        "    'fieldsofplay_tag_list',\n",
        "    f.when(f.col('fieldsofplay_tag_list').contains(\",\"), f.concat(f.col('construct_tag_list'), f.lit(\"_multiple_fop\"))).otherwise(f.col('fieldsofplay_tag_list'))\n",
        "  ).withColumn(\n",
        "    'division_tag_list',\n",
        "    f.when(f.col('division_tag_list').contains(\",\"), f.lit(\"multiple_division\")).otherwise(f.col('division_tag_list'))\n",
        "  ).withColumn(\n",
        "    'merchclass_tag_list',\n",
        "    f.when(f.col('merchclass_tag_list').contains(\",\"), f.lit(\"multiple_merchclass\")).otherwise(f.col('merchclass_tag_list'))\n",
        "  ).withColumn(\n",
        "    'sport_tag_list',\n",
        "    f.when(f.col('sport_tag_list').contains(\",\"), f.lit(\"multiple_sport\")).otherwise(f.col('sport_tag_list'))\n",
        "  ).withColumn(\n",
        "    'league_tag_list',\n",
        "    f.when(f.col('league_tag_list').contains(\",\"), f.lit(\"multiple_league\")).otherwise(f.col('league_tag_list'))\n",
        "  ).withColumn(\n",
        "    'athlete_tag_list',\n",
        "    f.when(f.col('athlete_tag_list').contains(\",\"), f.lit(\"multiple_athlete\")).otherwise(f.col('athlete_tag_list'))\n",
        "  ).withColumn(\n",
        "    'franchise_tag_list',\n",
        "    f.when(f.col('franchise_tag_list').contains(\",\"), f.lit(\"multiple_franchise\")).otherwise(f.col('franchise_tag_list'))\n",
        "  )\n",
        ")\n",
        "\n",
        "tbl_name = \"thread_nikeapp_automated_tags_list_no_metadata\"\n",
        "\n",
        "\"\"\"\n",
        "(\n",
        "  auto_tag_list\n",
        "  .write.format('delta')\n",
        "  .mode('overwrite')\n",
        "  .option('overwriteSchema', 'True')\n",
        "  .option('url', f's3://ngap2-user-data/gck/glbl_marsci_sandbox/owned/mchu10/{tbl_name}')\n",
        "  .saveAsTable(f'mchu10.{tbl_name}')\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "abbf2db0-3de2-44ab-a5ed-a6ff7fcf6dae",
          "showTitle": false,
          "title": ""
        },
        "id": "3QNPSKT6WBtf"
      },
      "outputs": [],
      "source": [
        "auto_tag_list = spark.sql(\"SELECT * FROM mchu10.thread_nikeapp_automated_tags_list_no_metadata\")\n",
        "auto_tag_list_df = auto_tag_list.toPandas()\n",
        "auto_tag_list_df['construct'] = auto_tag_list_df['construct'].str.replace(\"'\", \"\")\n",
        "display(auto_tag_list_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6cfd8898-97a9-4b2b-ac37-87a7bc8714fc",
          "showTitle": false,
          "title": ""
        },
        "id": "AsnkyddHWBtf"
      },
      "outputs": [],
      "source": [
        "eval_df = auto_tag_list_df[auto_tag_list_df['construct'].notnull()].copy()\n",
        "eval_df['correct'] = (eval_df['construct_tag_list'] == eval_df['construct']).astype(int)\n",
        "eval_df['construct_tag_list'] = eval_df['construct_tag_list'].fillna(\"Null Value\")\n",
        "print(\"'construct' accuracy (vs. CMS labels): {}\".format(eval_df['correct'].sum() / eval_df.shape[0]))\n",
        "\n",
        "values = list(set(eval_df['construct']))\n",
        "precision = []\n",
        "recall = []\n",
        "for value in values:\n",
        "  precision.append(precision_score(eval_df['construct'], eval_df['construct_tag_list'], labels=[value], average=None, zero_division=0)[0])\n",
        "  recall.append(recall_score(eval_df['construct'], eval_df['construct_tag_list'], labels=[value], average=None, zero_division=0)[0])\n",
        "metrics_df = pd.DataFrame({\n",
        "  'actual': values,\n",
        "  'precision': precision,\n",
        "  'recall': recall\n",
        "})\n",
        "display(metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5e27cd4f-91de-46c7-ae53-607dfe1e5055",
          "showTitle": false,
          "title": ""
        },
        "id": "b0HzPeP9WBtf"
      },
      "outputs": [],
      "source": [
        "auto_tag = spark.sql(\"SELECT * FROM mchu10.thread_nikeapp_automated_tags_no_metadata\")\n",
        "auto_tag_df = auto_tag.toPandas()\n",
        "auto_tag_df['sport_dimension'] = auto_tag_df['sport_dimension'].str.replace(\" \", \"\")\n",
        "auto_tag_df['sport_dimension'] = auto_tag_df['sport_dimension'].replace(\"\", None)\n",
        "display(auto_tag_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "71e467b2-cf50-4eb8-81ee-c97abdce1373",
          "showTitle": false,
          "title": ""
        },
        "id": "uXDeyI2hWBtf"
      },
      "outputs": [],
      "source": [
        "eval_df = auto_tag_df[(auto_tag_df['sport_dimension'].notnull()) & (auto_tag_df['sport_dimension'] != 'nikebyyou')].copy()\n",
        "\n",
        "values = list(set(eval_df['sport_dimension']))\n",
        "precision = []\n",
        "recall = []\n",
        "\n",
        "eval_df = pd.get_dummies(eval_df, columns=['sport_dimension'])\n",
        "\n",
        "for value in values:\n",
        "  precision.append(precision_score(eval_df[f'sport_dimension_{value}'], eval_df[f'{value}_tag'], zero_division=0))\n",
        "  recall.append(recall_score(eval_df[f'sport_dimension_{value}'], eval_df[f'{value}_tag'], zero_division=0))\n",
        "metrics_df = pd.DataFrame({\n",
        "  'actual': values,\n",
        "  'precision': precision,\n",
        "  'recall': recall\n",
        "})\n",
        "display(metrics_df)"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "mostRecentlyExecutedCommandWithImplicitDF": {
          "commandId": 2302655636037437,
          "dataframes": [
            "_sqldf"
          ]
        },
        "pythonIndentUnit": 2
      },
      "notebookName": "nike_app_threads_automated_tagging_v1_CLONE",
      "widgets": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}